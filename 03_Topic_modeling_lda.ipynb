{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import altair as alt\n",
    "from altair_saver import save\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data_mesh_publications_cleaned.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7407e32d-ad14-4c1d-a3ee-db18e023d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_custom_token_pattern(ngram_min, ngram_max):\n",
    "#     # Ensure no word repetition in n-grams\n",
    "#     word_pattern = r'\\b(\\w+)\\b(?=.*\\b\\1\\b)'\n",
    "    \n",
    "#     # Combine word patterns for specified n-gram range\n",
    "#     ngram_pattern = r'(?:' + word_pattern + r'\\s){' + str(ngram_min - 1) + r',' + str(ngram_max - 1) + r'}' + word_pattern\n",
    "    \n",
    "#     return ngram_pattern\n",
    "\n",
    "# token_pattern = generate_custom_token_pattern(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82da0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topics(text, tfidf_vectorizer, lda_model):\n",
    "    \n",
    "    # TF-IDF Vectorization for the specific document\n",
    "    tfidf_data = tfidf_vectorizer.transform([text])\n",
    "    tfidf_values = tfidf_data.toarray()\n",
    "    feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "    df_tfidf = pd.DataFrame(data=tfidf_values, columns=feature_names)\n",
    "\n",
    "    # Apply LDA\n",
    "    doc_topic_prob = lda_model.transform(df_tfidf)\n",
    "\n",
    "    # Get the most probable topic for the document\n",
    "    most_probable_topic = np.argmax(doc_topic_prob)\n",
    "\n",
    "    # Get the top words for the most probable topic with TF-IDF values\n",
    "    topic = lda_model.components_[most_probable_topic]\n",
    "    top_keywords_idx = topic.argsort()[:-10 - 1:-1]\n",
    "    top_keywords = [feature_names[i] for i in top_keywords_idx]\n",
    "    top_tfidf_values = [tfidf_vectorizer.idf_[tfidf_vectorizer.vocabulary_[word]] for word in top_keywords]\n",
    "#     top_tfidf_values = [tfidf_data[0, tfidf_vectorizer.vocabulary_[word]] for word in top_keywords]\n",
    "\n",
    "\n",
    "    topic_words = list(zip(top_keywords, top_tfidf_values))\n",
    "\n",
    "    return most_probable_topic + 1, topic_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05214e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 4), token_pattern=r'\\b\\w+\\b')\n",
    "tfidf_data = tfidf_vectorizer.fit_transform(df['Content'])\n",
    "\n",
    "# Apply LDA\n",
    "lda = LatentDirichletAllocation(n_components=38, random_state=42)\n",
    "lda.fit(tfidf_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e085e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'df' is your DataFrame with 'pdf_content' column\n",
    "df['topic'], df['topic_words'] = zip(*df.apply(lambda row: extract_topics(row['Content'], tfidf_vectorizer, lda), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe95a3f",
   "metadata": {},
   "source": [
    "# Results with filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3984aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = []\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    Filename = row['Filename']\n",
    "    topic_words = row['topic_words']\n",
    "\n",
    "    # Iterate through each tuple in the list of topic_words\n",
    "    for word, idf_value in topic_words:\n",
    "        result_data.append({'Filename': Filename, 'topic_word': word, 'idf_value': idf_value})\n",
    "\n",
    "# Create the result DataFrame from the list\n",
    "result_df = pd.DataFrame(result_data, columns=['Filename', 'topic_word', 'idf_value'])\n",
    "\n",
    "# Print the result DataFrame\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d020ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top terms for each PDF\n",
    "top_terms_df = result_df.groupby('Filename').head(10)\n",
    "\n",
    "# Add a small random value to 'idf_value' for better visualization\n",
    "top_terms_df['idf_value'] = top_terms_df['idf_value'] + np.random.rand(top_terms_df.shape[0]) * 0.0001\n",
    "\n",
    "# Create a base chart\n",
    "base = alt.Chart(top_terms_df).encode(\n",
    "    x=alt.X('rank:O', axis=None),  # Use rank for x-axis\n",
    "    y='Filename:N',\n",
    "    color=alt.Color('idf_value:Q', scale=alt.Scale(scheme='viridis')),\n",
    "    text='topic_word:N'  # Corrected column name to 'topic_word'\n",
    ").transform_window(\n",
    "    rank=\"rank()\",\n",
    "    sort=[alt.SortField(\"idf_value\", order=\"descending\")],\n",
    "    groupby=[\"Filename\"]\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "heatmap = base.mark_rect().encode(\n",
    "    color='idf_value:Q',\n",
    ")\n",
    "\n",
    "# Create text labels with conditional color\n",
    "text = base.mark_text(baseline='middle').encode(\n",
    "    text='topic_word:N',\n",
    "    color=alt.condition(alt.datum.idf_value >= 2.0, alt.value('white'), alt.value('black'))\n",
    ")\n",
    "\n",
    "# Display the heatmap and text labels\n",
    "chart_lda = (heatmap + text).properties(width=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ee3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save(chart_lda, \"lda_idf_heatmap.html\")\n",
    "chart_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c66e7d",
   "metadata": {},
   "source": [
    "# Result with publication type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data_publication_type = []\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    Publication_type = row['Publication_type']\n",
    "    topic_words = row['topic_words']\n",
    "\n",
    "    # Iterate through each tuple in the list of topic_words\n",
    "    for word, idf_value in topic_words:\n",
    "        result_data_publication_type.append({'Publication_type': Publication_type, 'topic_word': word, 'idf_value': idf_value})\n",
    "\n",
    "# Create the result DataFrame from the list\n",
    "result_df_publication_type = pd.DataFrame(result_data_publication_type, columns=['Publication_type', 'topic_word', 'idf_value'])\n",
    "\n",
    "# Print the result DataFrame\n",
    "result_df_publication_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2815735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top terms for each PDF\n",
    "top_terms_df_publication_type = result_df_publication_type.groupby('Publication_type').head(10)\n",
    "\n",
    "# Add a small random value to 'idf_value' for better visualization\n",
    "top_terms_df_publication_type['idf_value'] = top_terms_df_publication_type['idf_value'] + np.random.rand(top_terms_df_publication_type.shape[0]) * 0.0001\n",
    "\n",
    "# Create a base chart\n",
    "base = alt.Chart(top_terms_df_publication_type).encode(\n",
    "    x=alt.X('rank:O', axis=None),  # Use rank for x-axis\n",
    "    y='Publication_type:N',\n",
    "    color=alt.Color('idf_value:Q', scale=alt.Scale(scheme='viridis')),\n",
    "    text='topic_word:N'  # Corrected column name to 'topic_word'\n",
    ").transform_window(\n",
    "    rank=\"rank()\",\n",
    "    sort=[alt.SortField(\"idf_value\", order=\"descending\")],\n",
    "    groupby=[\"Publication_type\"]\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "heatmap = base.mark_rect().encode(\n",
    "    color='idf_value:Q',\n",
    ")\n",
    "\n",
    "# Create text labels with conditional color\n",
    "text = base.mark_text(baseline='middle').encode(\n",
    "    text='topic_word:N',\n",
    "    color=alt.condition(alt.datum.idf_value >= 2.0, alt.value('white'), alt.value('black'))\n",
    ")\n",
    "\n",
    "# Display the heatmap and text labels\n",
    "chart_lda_publication_type = (heatmap + text).properties(width=2000)\n",
    "chart_lda_publication_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b97296",
   "metadata": {},
   "source": [
    "# Result with publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data_publisher = []\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    Publisher = row['Publisher']\n",
    "    topic_words = row['topic_words']\n",
    "\n",
    "    # Iterate through each tuple in the list of topic_words\n",
    "    for word, idf_value in topic_words:\n",
    "        result_data_publisher.append({'Publisher': Publisher, 'topic_word': word, 'idf_value': idf_value})\n",
    "\n",
    "# Create the result DataFrame from the list\n",
    "result_df_publisher = pd.DataFrame(result_data_publisher)\n",
    "\n",
    "\n",
    "result_df_publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688338d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top terms for each PDF\n",
    "top_terms_df_publisher = result_df_publisher.groupby('Publisher').head(10)\n",
    "\n",
    "# Add a small random value to 'idf_value' for better visualization\n",
    "top_terms_df_publisher['idf_value'] = top_terms_df_publisher['idf_value'] + np.random.rand(top_terms_df_publisher.shape[0]) * 0.0001\n",
    "\n",
    "# Create a base chart\n",
    "base = alt.Chart(top_terms_df_publisher).encode(\n",
    "    x=alt.X('rank:O', axis=None),  # Use rank for x-axis\n",
    "    y='Publisher:N',\n",
    "    color=alt.Color('idf_value:Q', scale=alt.Scale(scheme='viridis')),\n",
    "    text='topic_word:N'  # Corrected column name to 'topic_word'\n",
    ").transform_window(\n",
    "    rank=\"rank()\",\n",
    "    sort=[alt.SortField(\"idf_value\", order=\"descending\")],\n",
    "    groupby=[\"Publisher\"]\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "heatmap = base.mark_rect().encode(\n",
    "    color='idf_value:Q',\n",
    ")\n",
    "\n",
    "# Create text labels with conditional color\n",
    "text = base.mark_text(baseline='middle').encode(\n",
    "    text='topic_word:N',\n",
    "    color=alt.condition(alt.datum.idf_value >= 3.0, alt.value('white'), alt.value('black'))\n",
    ")\n",
    "\n",
    "# Display the heatmap and text labels\n",
    "chart_lda_publisher = (heatmap + text).properties(width=1500)\n",
    "chart_lda_publisher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35feaca",
   "metadata": {},
   "source": [
    "# USING ONLY TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8503ad78-f4ca-4acf-99be-4031c8cf2f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save(chart_lda_publisher, 'lda_idf_heatmap_pub.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04341246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_words_for_each_document(df, num_top_words=10):\n",
    "\n",
    "    # Create a TF-IDF vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 4), token_pattern=r'\\b\\w+\\b')\n",
    "\n",
    "    # Fit and transform the PDF content\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['Content'])\n",
    "\n",
    "    # Get feature names (words) from the TF-IDF vectorizer\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Create a DataFrame with TF-IDF values\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "    # Now, for each document, find the top words based on TF-IDF scores\n",
    "    top_words_for_each_document = []\n",
    "    for i, row in enumerate(tfidf_df.iterrows()):\n",
    "        _, document_tfidf_scores = row\n",
    "        top_words_index = document_tfidf_scores.argsort()[-num_top_words:][::-1]\n",
    "        top_words = [(feature_names[index], document_tfidf_scores[index]) for index in top_words_index]\n",
    "        top_words_for_each_document.append(top_words)\n",
    "\n",
    "    # Create a new DataFrame with 'pdf_content' and 'top_words'\n",
    "    result_df = pd.DataFrame({'Filename': df['Filename'],'Publisher': df['Publisher'],'Publication_type': df['Publication_type'], 'Content': df['Content'], 'top_words': top_words_for_each_document})\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4787fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "result_df_tfidf = find_top_words_for_each_document(df)\n",
    "\n",
    "# Display the result DataFrame\n",
    "# result_df_tfidf['Publisher'] = df['Publisher']\n",
    "# result_df_tfidf['Publication_type'] = df['Publication_type']\n",
    "result_df_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022b088b",
   "metadata": {},
   "source": [
    "# Results with filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd770a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data_tfidf_filename = []\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "for _, row in result_df_tfidf.iterrows():\n",
    "    Filename = row['Filename']\n",
    "    top_words = row['top_words']\n",
    "\n",
    "    # Iterate through each tuple in the list of top_words\n",
    "    for word, tfidf in top_words:\n",
    "        result_data_tfidf_filename.append({'Filename': Filename, 'topic_word': word, 'tfidf_value': tfidf})\n",
    "\n",
    "# Create the result DataFrame from the list\n",
    "result_df_tfidf_filename = pd.DataFrame(result_data_tfidf_filename)\n",
    "\n",
    "result_df_tfidf_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748617f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming result_df_3 is your DataFrame\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', None) \n",
    "pd.set_option('display.max_colwidth', None)# Show all rows\n",
    "\n",
    "# Display the entire DataFrame\n",
    "print(result_df_tfidf_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7942654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top terms for each PDF\n",
    "top_terms_df_tfidf = result_df_tfidf_filename.groupby('Filename').head(10)\n",
    "\n",
    "# Add a small random value to 'idf_value' for better visualization\n",
    "top_terms_df_tfidf['tfidf_value'] = top_terms_df_tfidf['tfidf_value'] + np.random.rand(top_terms_df_tfidf.shape[0]) * 0.0001\n",
    "\n",
    "# Create a base chart\n",
    "base = alt.Chart(top_terms_df_tfidf).encode(\n",
    "    x=alt.X('rank:O', axis=None),  # Use rank for x-axis\n",
    "    y='Filename:N',\n",
    "    color=alt.Color('tfidf_value:Q', scale=alt.Scale(scheme='viridis')),\n",
    "    text='topic_word:N'  # Corrected column name to 'topic_word'\n",
    ").transform_window(\n",
    "    rank=\"rank()\",\n",
    "    sort=[alt.SortField(\"tfidf_value\", order=\"descending\")],\n",
    "    groupby=[\"Filename\"]\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "heatmap = base.mark_rect().encode(\n",
    "    color='tfidf_value:Q',\n",
    ")\n",
    "\n",
    "# Create text labels with conditional color\n",
    "text = base.mark_text(baseline='middle').encode(\n",
    "    text='topic_word:N',\n",
    "    color=alt.condition(alt.datum.tfidf_value >= 0.4, alt.value('white'), alt.value('black'))\n",
    ")\n",
    "\n",
    "# Display the heatmap and text labels\n",
    "chart_tfidf = (heatmap + text).properties(width=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2660fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save(chart_tfidf, 'tfidf_heatmap.html')\n",
    "chart_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b598002b",
   "metadata": {},
   "source": [
    "# Result with publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f585f4-9b3b-4461-84e5-f717ecede12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data_tfidf_publisher = []\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "for _, row in result_df_tfidf.iterrows():\n",
    "    Publisher = row['Publisher']\n",
    "    topic_words = row['top_words']\n",
    "\n",
    "    # Iterate through each tuple in the list of topic_words\n",
    "    for word, tfidf in topic_words:\n",
    "        result_data_tfidf_publisher.append({'Publisher': Publisher, 'top_word': word, 'tf_idf_value': tfidf})\n",
    "\n",
    "# Create the result DataFrame from the list\n",
    "result_df_tfidf_publisher = pd.DataFrame(result_data_tfidf_publisher)\n",
    "\n",
    "\n",
    "result_df_tfidf_publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb165b-e19c-481e-9a45-d2833079db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_tfidf_publisher.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65189ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top terms for each PDF\n",
    "top_terms_df_publisher = result_df_tfidf_publisher.groupby('Publisher').head(10)\n",
    "\n",
    "# Add a small random value to 'idf_value' for better visualization\n",
    "top_terms_df_publisher['tf_idf_value'] = top_terms_df_publisher['tf_idf_value'] + np.random.rand(top_terms_df_publisher.shape[0]) * 0.0001\n",
    "\n",
    "# Create a base chart\n",
    "base = alt.Chart(top_terms_df_publisher).encode(\n",
    "    x=alt.X('rank:O', axis=None),  # Use rank for x-axis\n",
    "    y='Publisher:N',\n",
    "    color=alt.Color('tf_idf_value:Q', scale=alt.Scale(scheme='viridis')),\n",
    "    text='top_word:N'  # Corrected column name to 'topic_word'\n",
    ").transform_window(\n",
    "    rank=\"rank()\",\n",
    "    sort=[alt.SortField(\"tf_idf_value\", order=\"descending\")],\n",
    "    groupby=[\"Publisher\"]\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "heatmap = base.mark_rect().encode(\n",
    "    color='tf_idf_value:Q',\n",
    ")\n",
    "\n",
    "# Create text labels with conditional color\n",
    "text = base.mark_text(baseline='middle').encode(\n",
    "    text='top_word:N',\n",
    "    color=alt.condition(alt.datum.tf_idf_value >= 0.4, alt.value('white'), alt.value('black'))\n",
    ")\n",
    "\n",
    "# Display the heatmap and text labels\n",
    "chart_publisher = (heatmap + text).properties(width=1500)\n",
    "chart_publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa374eb-e50a-47f5-ba20-26830d85b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save(chart_tfidf_publisher_2, 'tfidf_heatmap_publisher.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8bd49",
   "metadata": {},
   "source": [
    "# Results with Publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6106b801-7924-4c1d-9b42-4fa34ccc41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data_tfidf_publication_type = []\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "for _, row in result_df_tfidf.iterrows():\n",
    "    Publication_type = row['Publication_type']\n",
    "    topic_words = row['top_words']\n",
    "\n",
    "    # Iterate through each tuple in the list of topic_words\n",
    "    for word, tfidf in topic_words:\n",
    "        result_data_tfidf_publication_type.append({'Publication_type': Publication_type, 'top_word': word, 'tf_idf_value': tfidf})\n",
    "\n",
    "# Create the result DataFrame from the list\n",
    "result_df_tfidf_publication_type = pd.DataFrame(result_data_tfidf_publication_type)\n",
    "\n",
    "\n",
    "result_df_tfidf_publication_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top terms for each PDF\n",
    "top_terms_df_publication_type = result_df_tfidf_publication_type.groupby('Publication_type').head(10)\n",
    "\n",
    "# Add a small random value to 'idf_value' for better visualization\n",
    "top_terms_df_publication_type['tf_idf_value'] = top_terms_df_publication_type['tf_idf_value'] + np.random.rand(top_terms_df_publication_type.shape[0]) * 0.0001\n",
    "\n",
    "# Create a base chart\n",
    "base = alt.Chart(top_terms_df_publication_type).encode(\n",
    "    x=alt.X('rank:O', axis=None),  # Use rank for x-axis\n",
    "    y='Publication_type:N',\n",
    "    color=alt.Color('tf_idf_value:Q', scale=alt.Scale(scheme='viridis')),\n",
    "    text='top_word:N'  # Corrected column name to 'topic_word'\n",
    ").transform_window(\n",
    "    rank=\"rank()\",\n",
    "    sort=[alt.SortField(\"tf_idf_value\", order=\"descending\")],\n",
    "    groupby=[\"Publication_type\"]\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "heatmap = base.mark_rect().encode(\n",
    "    color='tf_idf_value:Q',\n",
    ")\n",
    "\n",
    "# Create text labels with conditional color\n",
    "text = base.mark_text(baseline='middle').encode(\n",
    "    text='top_word:N',\n",
    "    color=alt.condition(alt.datum.tf_idf_value >= 0.4, alt.value('white'), alt.value('black'))\n",
    ")\n",
    "\n",
    "# Display the heatmap and text labels\n",
    "chart_publication_type = (heatmap + text).properties(width=1500)\n",
    "chart_publication_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b04de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
