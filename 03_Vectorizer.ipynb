{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad80ccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sitas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\sitas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\sitas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from gensim import corpora, models\n",
    "# from gensim.models.ldamodel import LdaModel\n",
    "from nltk.tokenize import word_tokenize\n",
    "import altair as alt\n",
    "from altair_saver import save\n",
    "import os\n",
    "import re\n",
    "from nltk.util import ngrams\n",
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35d8e014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Content</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Year</th>\n",
       "      <th>Publication_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Breaking Down Data Silos Data Mesh to Achieve ...</td>\n",
       "      <td>abstract data localization law becoming make h...</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>2023</td>\n",
       "      <td>conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decentralized Data Governance as Part of a Dat...</td>\n",
       "      <td>abstract data socio technical decentralized an...</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>2023</td>\n",
       "      <td>conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enterprise Data Strategy A Decentralized Data ...</td>\n",
       "      <td>abstract enterprise experience exponential gro...</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>2022</td>\n",
       "      <td>conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finding Your Way Through the Jungle of Big Dat...</td>\n",
       "      <td>abstract paper present systematic ofcommon ana...</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>2021</td>\n",
       "      <td>conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CoK A Survey of Privacy Challenges in Relation...</td>\n",
       "      <td>growing volume data appear multiple dis tribut...</td>\n",
       "      <td>Springer</td>\n",
       "      <td>2022</td>\n",
       "      <td>conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Converging Data Mesh and Microservice Principl...</td>\n",
       "      <td>company invested driven design sup port data d...</td>\n",
       "      <td>Springer</td>\n",
       "      <td>2023</td>\n",
       "      <td>conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Integration Revitalized From Data Warehou...</td>\n",
       "      <td>year data integration architecture evolved fro...</td>\n",
       "      <td>Springer</td>\n",
       "      <td>2023</td>\n",
       "      <td>conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Mesh as Distributed Data Platform for Lar...</td>\n",
       "      <td>rapid increase data volume last decade promote...</td>\n",
       "      <td>Springer</td>\n",
       "      <td>2023</td>\n",
       "      <td>conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Fabric and Data Mesh Approaches with AI</td>\n",
       "      <td>look back data architecture developed response...</td>\n",
       "      <td>Springer</td>\n",
       "      <td>2023</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cow Mesh a data-mesh architecture to unify dai...</td>\n",
       "      <td>dairy economically signi cant industry caters ...</td>\n",
       "      <td>ResearchGate</td>\n",
       "      <td>2023</td>\n",
       "      <td>journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Mesh a Systematic Gray Literature Review</td>\n",
       "      <td>world living golden age data idc data corporat...</td>\n",
       "      <td>ResearchGate</td>\n",
       "      <td>2023</td>\n",
       "      <td>journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Mesh Motivational Factors Challenges and ...</td>\n",
       "      <td>volume data continues grow organization strivi...</td>\n",
       "      <td>ResearchGate</td>\n",
       "      <td>2023</td>\n",
       "      <td>preprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>From Data Mess to Data Mesh Solution for Futur...</td>\n",
       "      <td>technology advance data volume velocity increa...</td>\n",
       "      <td>ResearchGate</td>\n",
       "      <td>2023</td>\n",
       "      <td>journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Identifying Alternatives and Deciding Factors ...</td>\n",
       "      <td>data introduced new type data architecture pro...</td>\n",
       "      <td>ResearchGate</td>\n",
       "      <td>2022</td>\n",
       "      <td>conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Navigating the Data Architecture Landscape</td>\n",
       "      <td>rapidly evolving eld data numerous terminology...</td>\n",
       "      <td>ResearchGate</td>\n",
       "      <td>2023</td>\n",
       "      <td>preprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A Distributed Data Mesh Paradigm for an Event-...</td>\n",
       "      <td>smart capable independent action set rule trig...</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>2023</td>\n",
       "      <td>conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Mesh Concepts and Principles of a Paradig...</td>\n",
       "      <td>inherent growing varied form software applicat...</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>2021</td>\n",
       "      <td>conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Mesh A Holistic Examination Of Its Princi...</td>\n",
       "      <td>today live world important asset data accordin...</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>2023</td>\n",
       "      <td>master thesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Introducing Data Mesh paradigm for Smart City ...</td>\n",
       "      <td>concept smart city imposes unique set requirem...</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>2023</td>\n",
       "      <td>conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Towards avoiding the data mess Industry insigh...</td>\n",
       "      <td>volume data continues grow organization strivi...</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>2023</td>\n",
       "      <td>preprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Utilization of Data Mesh Framework as a Part o...</td>\n",
       "      <td>digital technology present almost every consum...</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>2021</td>\n",
       "      <td>master thesis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Filename  \\\n",
       "0   Breaking Down Data Silos Data Mesh to Achieve ...   \n",
       "1   Decentralized Data Governance as Part of a Dat...   \n",
       "2   Enterprise Data Strategy A Decentralized Data ...   \n",
       "3   Finding Your Way Through the Jungle of Big Dat...   \n",
       "4   CoK A Survey of Privacy Challenges in Relation...   \n",
       "5   Converging Data Mesh and Microservice Principl...   \n",
       "6   Data Integration Revitalized From Data Warehou...   \n",
       "7   Data Mesh as Distributed Data Platform for Lar...   \n",
       "8        Data Fabric and Data Mesh Approaches with AI   \n",
       "9   Cow Mesh a data-mesh architecture to unify dai...   \n",
       "10      Data Mesh a Systematic Gray Literature Review   \n",
       "11  Data Mesh Motivational Factors Challenges and ...   \n",
       "12  From Data Mess to Data Mesh Solution for Futur...   \n",
       "13  Identifying Alternatives and Deciding Factors ...   \n",
       "14         Navigating the Data Architecture Landscape   \n",
       "15  A Distributed Data Mesh Paradigm for an Event-...   \n",
       "16  Data Mesh Concepts and Principles of a Paradig...   \n",
       "17  Data Mesh A Holistic Examination Of Its Princi...   \n",
       "18  Introducing Data Mesh paradigm for Smart City ...   \n",
       "19  Towards avoiding the data mess Industry insigh...   \n",
       "20  Utilization of Data Mesh Framework as a Part o...   \n",
       "\n",
       "                                              Content      Publisher  Year  \\\n",
       "0   abstract data localization law becoming make h...           IEEE  2023   \n",
       "1   abstract data socio technical decentralized an...           IEEE  2023   \n",
       "2   abstract enterprise experience exponential gro...           IEEE  2022   \n",
       "3   abstract paper present systematic ofcommon ana...           IEEE  2021   \n",
       "4   growing volume data appear multiple dis tribut...       Springer  2022   \n",
       "5   company invested driven design sup port data d...       Springer  2023   \n",
       "6   year data integration architecture evolved fro...       Springer  2023   \n",
       "7   rapid increase data volume last decade promote...       Springer  2023   \n",
       "8   look back data architecture developed response...       Springer  2023   \n",
       "9   dairy economically signi cant industry caters ...   ResearchGate  2023   \n",
       "10  world living golden age data idc data corporat...   ResearchGate  2023   \n",
       "11  volume data continues grow organization strivi...   ResearchGate  2023   \n",
       "12  technology advance data volume velocity increa...   ResearchGate  2023   \n",
       "13  data introduced new type data architecture pro...   ResearchGate  2022   \n",
       "14  rapidly evolving eld data numerous terminology...   ResearchGate  2023   \n",
       "15  smart capable independent action set rule trig...       Elsevier  2023   \n",
       "16  inherent growing varied form software applicat...       Elsevier  2021   \n",
       "17  today live world important asset data accordin...  miscellaneous  2023   \n",
       "18  concept smart city imposes unique set requirem...  miscellaneous  2023   \n",
       "19  volume data continues grow organization strivi...  miscellaneous  2023   \n",
       "20  digital technology present almost every consum...  miscellaneous  2021   \n",
       "\n",
       "   Publication_type  \n",
       "0        conference  \n",
       "1        conference  \n",
       "2        conference  \n",
       "3        conference  \n",
       "4        conference  \n",
       "5        conference  \n",
       "6        conference  \n",
       "7        conference  \n",
       "8              book  \n",
       "9           journal  \n",
       "10          journal  \n",
       "11         preprint  \n",
       "12          journal  \n",
       "13       conference  \n",
       "14         preprint  \n",
       "15       conference  \n",
       "16       conference  \n",
       "17    master thesis  \n",
       "18       conference  \n",
       "19         preprint  \n",
       "20    master thesis  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data_mesh_publications_cleaned.csv')\n",
    "df_sample = df. copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35feaca",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b08ad6b-93e8-433d-81c1-37d6c80896b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Remove non-alphanumeric characters and special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s-]', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Preprocess the PDF content before fitting it to the TF-IDF vectorizer\n",
    "df['Content'] = df['Content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04341246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_top_words_for_each_document(df, num_top_words=5):\n",
    "\n",
    "#     # Create a TF-IDF vectorizer\n",
    "#     tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(2, 4), token_pattern=r'\\b\\w[\\w-]+\\b')\n",
    "\n",
    "#     # Fit and transform the PDF content\n",
    "#     tfidf_matrix = tfidf_vectorizer.fit_transform(df['Content'])\n",
    "\n",
    "#     # Get feature names (words) from the TF-IDF vectorizer\n",
    "#     feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "#     # Create a DataFrame with TF-IDF values\n",
    "#     tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "#     # Now, for each document, find the top words based on TF-IDF scores\n",
    "#     top_words_for_each_document = []\n",
    "#     for i, row in enumerate(tfidf_df.iterrows()):\n",
    "#         _, document_tfidf_scores = row\n",
    "#         top_words_index = document_tfidf_scores.argsort()[-num_top_words:][::-1]\n",
    "#         top_words = [(feature_names[index], document_tfidf_scores[index]) for index in top_words_index]\n",
    "#         top_words_for_each_document.append(top_words)\n",
    "\n",
    "#     # Create a new DataFrame with 'pdf_content' and 'top_words'\n",
    "#     result_df = pd.DataFrame({'Filename': df['Filename'],'Year': df['Year'],'Publisher': df['Publisher'],'Publication_type': df['Publication_type'], 'Content': df['Content'], 'top_words': top_words_for_each_document})\n",
    "\n",
    "#     return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7642815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_words_for_each_document(df, num_top_words=5):\n",
    "    df['Content'] = df['Content'].apply(preprocess_text)\n",
    "\n",
    "    # Create a TF-IDF vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(2, 4), token_pattern=r'\\b\\w[\\w-]+\\b')\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['Content'])\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Correcting split words in feature names\n",
    "    corrected_features = {name: name.replace('arti cial', 'artificial') for name in feature_names}\n",
    "    corrected_feature_names = [corrected_features[name] for name in feature_names]\n",
    "\n",
    "    # Create a DataFrame with corrected feature names and TF-IDF values\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=corrected_feature_names)\n",
    "\n",
    "    # Now, for each document, find the top words based on corrected TF-IDF scores\n",
    "    top_words_for_each_document = []\n",
    "    for i, row in tfidf_df.iterrows():\n",
    "        top_words_index = row.argsort()[-num_top_words:][::-1]\n",
    "        top_words = [(corrected_feature_names[index], row[index]) for index in top_words_index]\n",
    "        top_words_for_each_document.append(top_words)\n",
    "\n",
    "    # Create a new DataFrame with results\n",
    "    result_df = pd.DataFrame({\n",
    "        'Filename': df['Filename'],\n",
    "        'Year': df['Year'],\n",
    "        'Publisher': df['Publisher'],\n",
    "        'Publication_type': df['Publication_type'],\n",
    "        'Content': df['Content'],\n",
    "        'top_words': top_words_for_each_document\n",
    "    })\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4787fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "result_df_tfidf = find_top_words_for_each_document(df)\n",
    "#result_df_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022b088b",
   "metadata": {},
   "source": [
    "# Results with filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd770a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data_tfidf_filename = []\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "for _, row in result_df_tfidf.iterrows():\n",
    "    Filename = row['Filename']\n",
    "    top_words = row['top_words']\n",
    "\n",
    "    # Iterate through each tuple in the list of top_words\n",
    "    for word, tfidf in top_words:\n",
    "        result_data_tfidf_filename.append({'Filename': Filename, 'topic_word': word, 'tfidf_value': tfidf})\n",
    "\n",
    "# Create the result DataFrame from the list\n",
    "result_df_tfidf_filename = pd.DataFrame(result_data_tfidf_filename)\n",
    "\n",
    "# result_df_tfidf_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748617f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming result_df_3 is your DataFrame\n",
    "# pd.set_option('display.max_columns', None)  # Show all columns\n",
    "# pd.set_option('display.max_rows', None) \n",
    "# pd.set_option('display.max_colwidth', None)# Show all rows\n",
    "\n",
    "# Display the entire DataFrame\n",
    "result_df_tfidf_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7942654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top terms for each PDF\n",
    "top_terms_df_tfidf = result_df_tfidf_filename.groupby('Filename').head(5)\n",
    "\n",
    "# Add a small random value to 'idf_value' for better visualization\n",
    "top_terms_df_tfidf['tfidf_value'] = top_terms_df_tfidf['tfidf_value'] + np.random.rand(top_terms_df_tfidf.shape[0]) * 0.0001\n",
    "\n",
    "# Create a base chart\n",
    "base = alt.Chart(top_terms_df_tfidf).encode(\n",
    "    x=alt.X('rank:O', axis=None),  # Use rank for x-axis\n",
    "    y='Filename:N',\n",
    "    color=alt.Color('tfidf_value:Q', scale=alt.Scale(scheme='viridis')),\n",
    "    text='topic_word:N'  # Corrected column name to 'topic_word'\n",
    ").transform_window(\n",
    "    rank=\"rank()\",\n",
    "    sort=[alt.SortField(\"tfidf_value\", order=\"descending\")],\n",
    "    groupby=[\"Filename\"]\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "heatmap = base.mark_rect().encode(\n",
    "    color='tfidf_value:Q',\n",
    ")\n",
    "\n",
    "# Create text labels with conditional color\n",
    "text = base.mark_text(baseline='middle',fontWeight='bold').encode(\n",
    "    text='topic_word:N',\n",
    "    color=alt.condition(alt.datum.tfidf_value >= 0.4, alt.value('white'), alt.value('black'))\n",
    ")\n",
    "\n",
    "# Display the heatmap and text labels\n",
    "chart_tfidf = (heatmap + text).properties(width=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2660fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save(chart_tfidf, 'tfidf_heatmap.html')\n",
    "chart_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b598002b",
   "metadata": {},
   "source": [
    "# Result with publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f585f4-9b3b-4461-84e5-f717ecede12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data_tfidf_publisher = []\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "for _, row in result_df_tfidf.iterrows():\n",
    "    Publisher = row['Publisher']\n",
    "    topic_words = row['top_words']\n",
    "\n",
    "    # Iterate through each tuple in the list of topic_words\n",
    "    for word, tfidf in topic_words:\n",
    "        result_data_tfidf_publisher.append({'Publisher': Publisher, 'top_word': word, 'tf_idf_value': tfidf})\n",
    "\n",
    "# Create the result DataFrame from the list\n",
    "result_df_tfidf_publisher = pd.DataFrame(result_data_tfidf_publisher)\n",
    "\n",
    "\n",
    "result_df_tfidf_publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb165b-e19c-481e-9a45-d2833079db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_tfidf_publisher.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65189ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top terms for each PDF\n",
    "top_terms_df_publisher = result_df_tfidf_publisher.groupby('Publisher').head(5)\n",
    "\n",
    "# Add a small random value to 'idf_value' for better visualization\n",
    "top_terms_df_publisher['tf_idf_value'] = top_terms_df_publisher['tf_idf_value'] + np.random.rand(top_terms_df_publisher.shape[0]) * 0.0001\n",
    "\n",
    "# Create a base chart\n",
    "base = alt.Chart(top_terms_df_publisher).encode(\n",
    "    x=alt.X('rank:O', axis=None),  # Use rank for x-axis\n",
    "    y='Publisher:N',\n",
    "    color=alt.Color('tf_idf_value:Q', scale=alt.Scale(scheme='viridis')),\n",
    "    text='top_word:N'  # Corrected column name to 'topic_word'\n",
    ").transform_window(\n",
    "    rank=\"rank()\",\n",
    "    sort=[alt.SortField(\"tf_idf_value\", order=\"descending\")],\n",
    "    groupby=[\"Publisher\"]\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "heatmap = base.mark_rect().encode(\n",
    "    color='tf_idf_value:Q',\n",
    ")\n",
    "\n",
    "# Create text labels with conditional color\n",
    "text = base.mark_text(baseline='middle',fontWeight='bold').encode(\n",
    "    text='top_word:N',\n",
    "    color=alt.condition(alt.datum.tf_idf_value >= 0.4, alt.value('white'), alt.value('black'))\n",
    ")\n",
    "\n",
    "# Display the heatmap and text labels\n",
    "chart_publisher = (heatmap + text).properties(width=1300)\n",
    "chart_publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa374eb-e50a-47f5-ba20-26830d85b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save(chart_tfidf_publisher_2, 'tfidf_heatmap_publisher.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8bd49",
   "metadata": {},
   "source": [
    "# Results with Publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6106b801-7924-4c1d-9b42-4fa34ccc41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data_tfidf_publication_type = []\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "for _, row in result_df_tfidf.iterrows():\n",
    "    Publication_type = row['Publication_type']\n",
    "    topic_words = row['top_words']\n",
    "\n",
    "    # Iterate through each tuple in the list of topic_words\n",
    "    for word, tfidf in topic_words:\n",
    "        result_data_tfidf_publication_type.append({'Publication_type': Publication_type, 'top_word': word, 'tf_idf_value': tfidf})\n",
    "\n",
    "# Create the result DataFrame from the list\n",
    "result_df_tfidf_publication_type = pd.DataFrame(result_data_tfidf_publication_type)\n",
    "\n",
    "\n",
    "result_df_tfidf_publication_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top terms for each PDF\n",
    "top_terms_df_publication_type = result_df_tfidf_publication_type.groupby('Publication_type').head(5)\n",
    "\n",
    "# Add a small random value to 'idf_value' for better visualization\n",
    "top_terms_df_publication_type['tf_idf_value'] = top_terms_df_publication_type['tf_idf_value'] + np.random.rand(top_terms_df_publication_type.shape[0]) * 0.0001\n",
    "\n",
    "# Create a base chart\n",
    "base = alt.Chart(top_terms_df_publication_type).encode(\n",
    "    x=alt.X('rank:O', axis=None),  # Use rank for x-axis\n",
    "    y='Publication_type:N',\n",
    "    color=alt.Color('tf_idf_value:Q', scale=alt.Scale(scheme='viridis')),\n",
    "    text='top_word:N'  # Corrected column name to 'topic_word'\n",
    ").transform_window(\n",
    "    rank=\"rank()\",\n",
    "    sort=[alt.SortField(\"tf_idf_value\", order=\"descending\")],\n",
    "    groupby=[\"Publication_type\"]\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "heatmap = base.mark_rect().encode(\n",
    "    color='tf_idf_value:Q',\n",
    ")\n",
    "\n",
    "# Create text labels with conditional color\n",
    "text = base.mark_text(baseline='middle',fontWeight='bold').encode(\n",
    "    text='top_word:N',\n",
    "    color=alt.condition(alt.datum.tf_idf_value >= 0.4, alt.value('white'), alt.value('black'))\n",
    ")\n",
    "\n",
    "# Display the heatmap and text labels\n",
    "chart_publication_type = (heatmap + text).properties(width=1300)\n",
    "chart_publication_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data_tfidf_date = []\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "for _, row in result_df_tfidf.iterrows():\n",
    "    Year = row['Year']\n",
    "    topic_words = row['top_words']\n",
    "\n",
    "    # Iterate through each tuple in the list of topic_words\n",
    "    for word, tfidf in topic_words:\n",
    "        result_data_tfidf_date.append({'Year': Year, 'top_word': word, 'tf_idf_value': tfidf})\n",
    "\n",
    "# Create the result DataFrame from the list\n",
    "result_data_tfidf_date = pd.DataFrame(result_data_tfidf_date)\n",
    "\n",
    "\n",
    "result_data_tfidf_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a622092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top terms for each PDF\n",
    "top_terms_df_tfidf_dates = result_data_tfidf_date.groupby('Year').head(5)\n",
    "\n",
    "# Add a small random value to 'idf_value' for better visualization\n",
    "top_terms_df_tfidf_dates['tf_idf_value'] = top_terms_df_tfidf_dates['tf_idf_value'] + np.random.rand(top_terms_df_tfidf_dates.shape[0]) * 0.0001\n",
    "\n",
    "# Create a base chart\n",
    "# Create a base chart\n",
    "base = alt.Chart(top_terms_df_tfidf_dates).encode(\n",
    "    x=alt.X('rank:O', axis=None),  # Use rank for x-axis\n",
    "    y='Year:N',\n",
    "    color=alt.Color('tf_idf_value:Q', scale=alt.Scale(scheme='viridis')),\n",
    "    text='top_word:N'  # Corrected column name to 'topic_word'\n",
    ").transform_window(\n",
    "    rank=\"rank()\",\n",
    "    sort=[alt.SortField(\"tf_idf_value\", order=\"descending\")],\n",
    "    groupby=[\"Year\"]\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "heatmap = base.mark_rect().encode(\n",
    "    color='tf_idf_value:Q',\n",
    ")\n",
    "\n",
    "# Create text labels with conditional color\n",
    "text = base.mark_text(baseline='middle',fontWeight='bold').encode(\n",
    "    text='top_word:N',\n",
    "    color=alt.condition(alt.datum.tf_idf_value >= 0.4, alt.value('white'), alt.value('black'))\n",
    ")\n",
    "\n",
    "# Display the heatmap and text labels\n",
    "chart_date_tfidf_type = (heatmap + text).properties(width=1300)\n",
    "chart_date_tfidf_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b325a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
